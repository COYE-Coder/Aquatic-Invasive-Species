{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages: \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "# Required if you don't have an environment variable setup with the Authentication Key:\n",
    "# ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatially thin locations and export to asset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS\n",
    "#//========================================================\n",
    "\n",
    "def filterDistance(points, distance):\n",
    "    # Spatial thinning function\n",
    "    def iter_func(el, ini):\n",
    "        ini = ee.List(ini)\n",
    "        fcini = ee.FeatureCollection(ini)\n",
    "        buf = ee.Feature(el).geometry().buffer(distance)\n",
    "        s = fcini.filterBounds(buf).size()\n",
    "        cond = s.lte(0)\n",
    "        return ee.Algorithms.If(cond, ini.add(el), ini)\n",
    "    filt2 = ee.List([])\n",
    "    filt = points.iterate(iter_func, filt2)\n",
    "    filtered = ee.FeatureCollection(ee.List(filt))\n",
    "    return filtered\n",
    "\n",
    "#//========================================================\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate list so that thinning algorithm can be performed in a spatially explicit manner\n",
    "s_dates = ee.List([\n",
    "ee.Date('2001-01-01'),ee.Date('2002-01-01'),\n",
    "ee.Date('2003-01-01'),ee.Date('2004-01-01'),\n",
    "ee.Date('2005-01-01'),ee.Date('2006-01-01'),\n",
    "ee.Date('2007-01-01'),ee.Date('2008-01-01'),\n",
    "ee.Date('2009-01-01'),ee.Date('2010-01-01'),\n",
    "ee.Date('2011-01-01'),ee.Date('2012-01-01'),\n",
    "ee.Date('2013-01-01'),ee.Date('2015-01-01'),\n",
    "ee.Date('2016-01-01'),ee.Date('2017-01-01')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that filters the feature collection and spatially thins it\n",
    "def filter_date_space(date):\n",
    "    start_date = ee.Date(date).advance(1,'year')\n",
    "    end_date = start_date.advance(1,'year')\n",
    "    points_in_that_year = coll.filterDate(start_date, end_date)\n",
    "    \n",
    "    spatially_filt = filterDistance(points_in_that_year, distance)\n",
    "    \n",
    "    return spatially_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "carp_og = ee.FeatureCollection(\"users/seancliffcarter/PresenceData/Asian_Carp\"),\n",
    "quagga_og = ee.FeatureCollection(\"users/seancliffcarter/PresenceData/Quagga_clean\"),\n",
    "hydrilla_og = ee.FeatureCollection(\"users/seancliffcarter/PresenceData/hydrilla_clean\"),\n",
    "zebra_og = ee.FeatureCollection(\"users/seancliffcarter/zebra_clean\"),\n",
    "snakehead_og = ee.FeatureCollection(\"users/seancliffcarter/snakehead_clean\");\n",
    "\n",
    "coll = ee.FeatureCollection(zebra_og) # <----- CHANGE NAME FOR DIFFERENT DATASETS\n",
    "distance = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform spatial thinning algorithm and export to asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = s_dates.map(filter_date_space)\n",
    "def merge_coll(first_year, second_year):\n",
    "    return ee.FeatureCollection(first_year).merge(ee.FeatureCollection(second_year))\n",
    "\n",
    "first = ee.FeatureCollection([])\n",
    "spatially_thin = ee.FeatureCollection(feats.iterate(merge_coll, first))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export = ee.batch.Export.table.toAsset(collection = spatially_thin,\n",
    "                    description = 'zebra_spatially_thinned', # <-------- CHANGE NAME FOR DIFFERENT DATA\n",
    "                    assetId = 'users/seancliffcarter/spatially_thinned/zebra')# <----- CHANGE NAME\n",
    "export.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Big Raster Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIS Mission\n",
    "modusGlobal = ee.ImageCollection(\"MODIS/006/MYD11A2\")\n",
    "\n",
    "# Primary Productivity\n",
    "GPP = ee.ImageCollection(\"UMT/NTSG/v2/LANDSAT/GPP\")\n",
    "\n",
    "# Surface water\n",
    "pikelSurfaceWater = ee.Image(\"JRC/GSW1_1/GlobalSurfaceWater\")\n",
    "\n",
    "# Elevation\n",
    "DEM = ee.Image(\"USGS/NED\")\n",
    "\n",
    "# Enhanced Vegetation Index and NDVI\n",
    "modusVeg = ee.ImageCollection(\"MODIS/006/MYD13A2\")\n",
    "\n",
    "# Heat Isolation Load\n",
    "CHILI = ee.Image(\"CSP/ERGo/1_0/Global/SRTM_CHILI\")\n",
    "\n",
    "# Topographic Diversity\n",
    "topoDiversity = ee.Image(\"CSP/ERGo/1_0/Global/ALOS_topoDiversity\")\n",
    "\n",
    "# Vegetation Continuous Field product - percent tree cover, etc\n",
    "VCF = ee.ImageCollection(\"MODIS/006/MOD44B\")\n",
    "\n",
    "# Human Modification index\n",
    "gHM = ee.ImageCollection(\"CSP/HM/GlobalHumanModification\")\n",
    "\n",
    "\n",
    "# Climate information\n",
    "NLDAS = ee.ImageCollection(\"NASA/NLDAS/FORA0125_H002\")\n",
    "\n",
    "# Shape file containing Country Boundaries\n",
    "countries = ee.FeatureCollection(\"USDOS/LSIB_SIMPLE/2017\")\n",
    "\n",
    "# Dynamic Surface Water metric\n",
    "pekel_monthly_water = ee.ImageCollection(\"JRC/GSW1_2/MonthlyHistory\")\n",
    "\n",
    "# Static surface water metric\n",
    "pekel_static_water = ee.ImageCollection('JRC/GSW1_2/MonthlyRecurrence')\n",
    "\n",
    "# SPATIALLY THINNED FEATURE COLLECTIONS- Exported from above script\n",
    "zebra = ee.FeatureCollection(\"users/seancliffcarter/PresenceData/zebra_spatially_thinned\")\n",
    "carp = ee.FeatureCollection(\"users/seancliffcarter/PresenceData/carp_spatially_thinned\")\n",
    "quagga = ee.FeatureCollection(\"users/seancliffcarter/PresenceData/quagga_spatially_thinned\")\n",
    "snake = ee.FeatureCollection(\"users/seancliffcarter/PresenceData/snake_spatially_thinned\")\n",
    "hydrilla = ee.FeatureCollection(\"users/seancliffcarter/hydrilla_spatiallythinned\")\n",
    "\n",
    "\n",
    "# Hydrilla Geometry (drawn manually)\n",
    "geometry = ee.Geometry.Polygon(\n",
    "        [[[-100.95683057308197, 47.53111193980715],\n",
    "          [-100.95683057308197, 25.104255042806013],\n",
    "          [-68.43729932308199, 25.104255042806013],\n",
    "          [-68.43729932308199, 47.53111193980715]]], None, False)\n",
    "\n",
    "# Helper function to embedd ee.FeatureCollections with EE readible date\n",
    "def embedd_date(x):\n",
    "    year = ee.Number(x.get(\"year\")).floor()\n",
    "    ee_date = ee.Date.fromYMD(year, 1, 15)\n",
    "    return x.set(\"system:time_start\", ee_date)\n",
    "\n",
    "# zebra = zebra.map(embedd_date)\n",
    "# carp = carp.map(embedd_date)\n",
    "# quagga = quagga.map(embedd_date)\n",
    "# snake = snake.map(embedd_date)\n",
    "hydrilla = hydrilla.map(embedd_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select features, etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================\n",
    "#Rename Bands and select bands, etc\n",
    "#========================================================\n",
    "\n",
    "\n",
    "NLDAS_precip = NLDAS.select(\"total_precipitation\");\n",
    "NLDAS_temp = NLDAS.select(\"temperature\");\n",
    "NLDAS_humid = NLDAS.select(\"specific_humidity\");\n",
    "NLDAS_potEvap = NLDAS.select(\"potential_evaporation\");\n",
    "\n",
    "\n",
    "CHILI = CHILI.rename(['Heat_Insolation_Load'])\n",
    "srtmChili = CHILI.select('Heat_Insolation_Load');\n",
    "topoDiversity = topoDiversity.rename([\"Topographic_Diversity\"])\n",
    "topoDiv = topoDiversity.select(\"Topographic_Diversity\")\n",
    "footprint = ee.Image(gHM.first().select(\"gHM\"));\n",
    "\n",
    "# Surface water occurrence\n",
    "sw_occurrence = pekel_static_water\\\n",
    "                      .select('monthly_recurrence')\\\n",
    "                      .mean()\\\n",
    "                      .rename(['SurfaceWaterOccurrence'])\\\n",
    "                      .unmask()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask features by quality control bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# Masking TPP via quality control bands\n",
    "# ========================================================\n",
    "def gpp_qc(img):\n",
    "    img2 = img.rename(['GPP','QC']);\n",
    "    quality = img2.select(\"QC\")\n",
    "    mask = quality.neq(11) \\\n",
    "                .And(quality.neq(10)) \\\n",
    "                .And(quality.neq(20)) \\\n",
    "                .And(quality.neq(21)) \n",
    "    return img2.mask(mask)\n",
    "\n",
    "GPP_QC = GPP.map(gpp_qc);\n",
    "\n",
    "# ========================================================\n",
    "# Masking LST via quality control bands\n",
    "# ========================================================\n",
    "def lst_qc(img):\n",
    "    quality = img.select(\"QC_Day\")\n",
    "    mask = quality.bitwiseAnd(3).eq(0) \\\n",
    "                .And(quality.bitwiseAnd(12).eq(0))\n",
    "    return img.mask(mask)\n",
    "\n",
    "LST = modusGlobal.map(lst_qc) \\\n",
    "                 .select(\"LST_Day_1km\");\n",
    "\n",
    "        \n",
    "# ========================================================\n",
    "# Mask Modus Vegetation Indices by quality flag\n",
    "# ========================================================\n",
    "def modusQC(image):\n",
    "    quality = image.select(\"SummaryQA\")\n",
    "    mask = quality.eq(0)\n",
    "    return image.updateMask(mask)\n",
    "\n",
    "modusVeg_QC = modusVeg.map(modusQC)\n",
    "EVI = modusVeg_QC.select(\"EVI\")\n",
    "NDVI = modusVeg_QC.select(\"NDVI\")\n",
    "\n",
    "# ========================================================\n",
    "# Mask Continuous Fields via quality control band\n",
    "# ========================================================\n",
    "def VCFqc(img):\n",
    "    quality = img.select(\"Quality\")\n",
    "    mask = quality.bitwiseAnd(2).eq(0) \\\n",
    "                    .And(quality.bitwiseAnd(4).eq(0)) \\\n",
    "                    .And(quality.bitwiseAnd(8).eq(0)) \\\n",
    "                    .And(quality.bitwiseAnd(16).eq(0)) \\\n",
    "                    .And(quality.bitwiseAnd(32).eq(0))\n",
    "\n",
    "    return img.mask(quality)\n",
    "\n",
    "VCF_qc = VCF.map(VCFqc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define helper filters and lists to iterate over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#========================================================\n",
    "# Define convex hull from which to draw pseudo absences\n",
    "#========================================================\n",
    "# Define CONUS\n",
    "CONUS = countries.filter(ee.Filter.eq(\"country_co\",\"US\")) \\\n",
    "                  .filter(ee.Filter.eq(\"country_na\",\"United States\"))\n",
    "\n",
    "zebra_hull = zebra.geometry().convexHull().intersection(CONUS)\n",
    "carp_hull = carp.geometry().convexHull().intersection(CONUS)\n",
    "quagga_hull = quagga.geometry().convexHull().intersection(CONUS)\n",
    "snake_hull = snake.geometry().convexHull().intersection(CONUS)\n",
    "hydrilla_hull = hydrilla.geometry().convexHull().intersection(CONUS)\n",
    "\n",
    "#========================================================\n",
    "\n",
    "\n",
    "#========================================================\n",
    "# Build Lists from which to map over\n",
    "#========================================================\n",
    "\n",
    "# List from which absences will be built\n",
    "ee_dates = ee.List([\n",
    "    ee.Date('2001-01-01'),ee.Date('2002-01-01'),\n",
    "    ee.Date('2003-01-01'),ee.Date('2004-01-01'),\n",
    "    ee.Date('2005-01-01'),ee.Date('2006-01-01'),\n",
    "    ee.Date('2007-01-01'),ee.Date('2008-01-01'),\n",
    "    ee.Date('2009-01-01'),ee.Date('2010-01-01'),\n",
    "    ee.Date('2011-01-01'),ee.Date('2012-01-01'),\n",
    "    ee.Date('2013-01-01'),ee.Date('2015-01-01'),\n",
    "    ee.Date('2016-01-01'),ee.Date('2017-01-01')])\n",
    "\n",
    "# Required for exporting presence locations due to covariate availability \n",
    "ee_dates_presence = ee.List([\n",
    "    ee.Date('2001-01-01'),ee.Date('2002-01-01'),\n",
    "    ee.Date('2003-01-01'),ee.Date('2004-01-01'),\n",
    "    ee.Date('2005-01-01'),ee.Date('2006-01-01'),\n",
    "    ee.Date('2007-01-01'),ee.Date('2008-01-01'),\n",
    "    ee.Date('2009-01-01'),ee.Date('2010-01-01'),\n",
    "    ee.Date('2011-01-01'),ee.Date('2012-01-01'),\n",
    "    ee.Date('2013-01-01'),ee.Date('2015-01-01'),\n",
    "    ee.Date('2016-01-01')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annual Cube function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================\n",
    "# \"Builder Function\" -- processes each annual variable into a list of images\n",
    "#========================================================\n",
    "\n",
    "def build_annual_cube(d):\n",
    "    # Set start and end dates for filtering time dependent predictors (SR, NDVI, Phenology)\n",
    "      # Advance startDate by 1 to begin with to account for water year (below)\n",
    "    startDate = (ee.Date(d).advance(1.0,'year').millis())\n",
    "    endDate = ee.Date(d).advance(2.0,'year').millis()\n",
    "\n",
    "  #========================================================\n",
    "  #Define function to compute seasonal information for a given variable\n",
    "  #========================================================\n",
    "    def add_seasonal_info(imgCol,name,bandName):\n",
    "        winter = imgCol.filterDate(winter_start,winter_end)\n",
    "        spring = imgCol.filterDate(spring_start,spring_end)\n",
    "        summer = imgCol.filterDate(summer_start,summer_end)\n",
    "        fall = imgCol.filterDate(fall_start,fall_end)\n",
    "\n",
    "        winter_tot = winter.sum()\n",
    "        spring_tot = spring.sum()\n",
    "        summer_tot = summer.sum()\n",
    "        fall_tot = fall.sum()\n",
    "\n",
    "        winter_max = winter.max()\n",
    "        winter_min = winter.min()\n",
    "        spring_max = spring.max()\n",
    "        spring_min = spring.min()\n",
    "        summer_max = summer.max()\n",
    "        summer_min = summer.min()\n",
    "        fall_max = fall.max()\n",
    "        fall_min = fall.min()\n",
    "\n",
    "        winter_diff = winter_max.subtract(winter_min)\n",
    "        spring_diff = spring_max.subtract(spring_min)\n",
    "        summer_diff = summer_max.subtract(summer_min)\n",
    "        fall_diff = fall_max.subtract(fall_min)\n",
    "\n",
    "        names = ['winter_total'+name,'spring_total'+name,'summer_total'+name,\n",
    "                      'fall_total'+name]\n",
    "\n",
    "        return winter_tot.addBands([spring_tot,summer_tot,fall_tot]) \\\n",
    "                         .rename(names)\n",
    "\n",
    "  # Set up Seasonal dates for precip, seasonal predictors\n",
    "    winter_start = ee.Date(startDate)\n",
    "    winter_end = ee.Date(startDate).advance(3,'month')\n",
    "    spring_start = ee.Date(startDate).advance(3,'month')\n",
    "    spring_end = ee.Date(startDate).advance(6,'month')\n",
    "    summer_start = ee.Date(startDate).advance(6,'month')\n",
    "    summer_end = ee.Date(startDate).advance(9,'month')\n",
    "    fall_start = ee.Date(startDate).advance(9,'month')\n",
    "    fall_end = ee.Date(endDate)\n",
    "\n",
    "  # Aggregate seasonal info for each variable of interest (potEvap neglected purposefully)\n",
    "    seasonal_precip = add_seasonal_info(NLDAS_precip,\"Precip\",\"total_precipitation\")\n",
    "    seasonal_temp = add_seasonal_info(NLDAS_temp,\"Temp\",\"temperature\")\n",
    "    seasonal_humid = add_seasonal_info(NLDAS_humid,\"Humidity\",\"specific_humidity\")\n",
    "\n",
    "    waterYear_start = ee.Date(startDate).advance(10,'month')\n",
    "    waterYear_end = waterYear_start.advance(1,'year')\n",
    "\n",
    "  #========================================================\n",
    "  # Aggregate Other Covariates\n",
    "  #========================================================\n",
    "\n",
    "  # Vegetative Continuous Fields\n",
    "    meanVCF = VCF_qc.filterDate(startDate, endDate) \\\n",
    "                      .mean()\n",
    "\n",
    "  # Filter Precip by water year to get total precip annually\n",
    "\n",
    "    waterYearTot = NLDAS_precip.filterDate(waterYear_start,waterYear_end) \\\n",
    "                                 .sum()\n",
    "\n",
    "  # Find mean EVI per year:\n",
    "    maxEVI = EVI.filterDate(startDate,endDate) \\\n",
    "                  .mean() \\\n",
    "                  .rename(['Mean_EVI'])\n",
    "\n",
    "  #Find mean NDVI per year:\n",
    "    maxNDVI = NDVI.filterDate(startDate,endDate) \\\n",
    "                    .mean() \\\n",
    "                    .rename([\"Mean_NDVI\"])\n",
    "\n",
    "  # Find flashiness per year by taking a Per-pixel Standard Deviation:\n",
    "    flashiness_yearly = ee.Image(pekel_monthly_water.filterDate(startDate,endDate) \\\n",
    "                                                      .reduce(ee.Reducer.sampleStdDev()) \\\n",
    "                                                      .select([\"water_stdDev\"])) \\\n",
    "                                                      .rename(\"Flashiness\")\n",
    "\n",
    "  # Find max LST per year:\n",
    "    maxLST = LST.max().rename([\"Max_LST_Annual\"])\n",
    "\n",
    "  # Find mean GPP per year:\n",
    "    maxGPP = GPP_QC.filterDate(startDate,endDate) \\\n",
    "                      .mean() \\\n",
    "                      .rename(['Mean_GPP','QC'])\n",
    "\n",
    "  # All banded images that don't change over time\n",
    "    static_input_bands = sw_occurrence.addBands(DEM.select(\"elevation\")) \\\n",
    "                                          .addBands(srtmChili) \\\n",
    "                                          .addBands(topoDiv) \\\n",
    "                                          .addBands(footprint)\n",
    "\n",
    "  # Construct huge banded image\n",
    "    banded_image = static_input_bands \\\n",
    "                          .addBands(srcImg = maxLST, names = [\"Max_LST_Annual\"]) \\\n",
    "                          .addBands(srcImg = maxGPP, names = [\"Mean_GPP\"]) \\\n",
    "                          .addBands(srcImg =  maxNDVI, names = [\"Mean_NDVI\"]) \\\n",
    "                          .addBands(srcImg = maxEVI, names = [\"Mean_EVI\"]) \\\n",
    "                          .addBands(meanVCF.select(\"Percent_Tree_Cover\")) \\\n",
    "                          .addBands(seasonal_precip) \\\n",
    "                          .addBands(flashiness_yearly) \\\n",
    "                          .set(\"system:time_start\",startDate)\n",
    "\n",
    "    return banded_image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#========================================================\n",
    "# Run covariate algorithm and build a huge image\n",
    "# with one band corresponding to each year / covariate\n",
    "#========================================================\n",
    "\n",
    "# Image Collection\n",
    "banded_images = ee.ImageCollection(ee_dates.map(build_annual_cube))\n",
    "\n",
    "def format_date(image):\n",
    "    dateFormatted = ee.String('_').cat(image.date().format('YYYY'))\n",
    "    return image.rename(image.bandNames().map(lambda x: ee.String(x).cat(dateFormatted)))\n",
    "\n",
    "    \n",
    "# Rename Image Collection so that each image is named by year\n",
    "renamed_collection = banded_images.map(format_date)\n",
    "\n",
    "\n",
    "# Squash big image collection down to one (LARGE!) image\n",
    "big_img = renamed_collection.toBands().regexpRename('^(.*)', 'b_$1')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PseudoAbsence Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#========================================================\n",
    "# Sample locations at each presence / \"absence\" location\n",
    "#========================================================\n",
    "# Helper function to include \"Presence\" Column\n",
    "def embedd_presence(feat):\n",
    "    return feat.set(\"Present\", 0)\n",
    "\n",
    "count = 0\n",
    "while count < 300:\n",
    "    # Sample from large image, with a different set of points for each \"count\"\n",
    "    absence_samp = big_img.sample(**{'region':zebra_hull, # <-------- CHANGE HULL TO SPECIES\n",
    "                                'scale':30,\n",
    "                                'numPixels':20,\n",
    "                                'seed': count,\n",
    "                                'dropNulls':False}).map(embedd_presence)\n",
    "\n",
    "    # Convert EE object to python JSON\n",
    "    absence_json = absence_samp.getInfo()\n",
    "    \n",
    "    # Get each feature in the sample\n",
    "    list_of_features = absence_json['features']\n",
    "    \n",
    "    # List comprehension to receive columns (\"propreties\") for each feature\n",
    "    new_data = [x['properties'] for x in list_of_features]\n",
    "\n",
    "    # Write directly to hard drive\n",
    "    pd.DataFrame(new_data).to_csv(\"Zebra/Absences/another_100_\"+str(count)+\".csv\",index=False) # < ----- CHANGE CSV NAME\n",
    "    \n",
    "    # Iterate so that we draw a different sample in next pass through\n",
    "    count += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample image collection with temporally explicit presence information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of sampling from the large image, we must sample from a temporally filtered image.\n",
    "banded_images = ee.ImageCollection(ee_dates_presence.map(build_annual_cube))\n",
    "\n",
    "\n",
    "def sample_from_collection(d):\n",
    "    # Set start and end dates for filtering time dependent predictors (SR, NDVI, Phenology)\n",
    "      # Advance startDate by 1 to begin with to account for water year (below)\n",
    "    startDate = (ee.Date(d).advance(1.0,'year').millis())\n",
    "    endDate = ee.Date(d).advance(2.0,'year').millis()\n",
    "    \n",
    "     # Filter points by dates\n",
    "    pointsInThatYear = zebra.filterDate(startDate, endDate) # <---- CHANGE ACCORDING TO SPECIES OF INTEREST\n",
    "    \n",
    "    # Filter collection by that year\n",
    "    img_in_that_year = ee.Image(banded_images.filterDate(startDate,endDate).first())\n",
    "    \n",
    "    \n",
    "    # Sample that image\n",
    "    presence_samp = img_in_that_year.unmask().sampleRegions(**{\n",
    "                                'collection':pointsInThatYear,\n",
    "                                'scale': 30,\n",
    "                                'properties':['Present'],\n",
    "                                'tileScale':16\n",
    "                              })\n",
    "    \n",
    "    return presence_samp\n",
    "\n",
    "# Return Feature Collection which can be exported\n",
    "presence_sample = ee.FeatureCollection(ee_dates_presence.map(sample_from_collection)).flatten()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter and output flattened feature collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedd Feature collection with random column to split it up\n",
    "embedded = presence_sample.randomColumn() #  <- MAKE SURE FEATURE COLLECTION IS CORRECT\n",
    "\n",
    "# Define a sequence of numbers (0,49)\n",
    "numpy_int_seq = np.arange(0,49,1)\n",
    "\n",
    "# Define sequence of decimals from which we can filter (0,0.02,0.04,...0.98)\n",
    "numpy_rand_seq = np.arange(0,1,0.02)\n",
    "\n",
    "def filter_and_output_features(s):\n",
    "    \n",
    "    # Greater than and less than values from which to filter\n",
    "    gt_val = ee.Number(numpy_rand_seq[s])\n",
    "    lt_val = ee.Number(numpy_rand_seq[s+1])\n",
    "    \n",
    "    # Instantiate filters\n",
    "    filt = ee.Filter.rangeContains('random', gt_val, lt_val)\n",
    "    filtered = embedded.filter(filt)\n",
    "    \n",
    "    \n",
    "    # Perform python-fu to export dataframe\n",
    "    presence_json = filtered.getInfo()\n",
    "\n",
    "    list_of_features = presence_json['features']\n",
    "\n",
    "    new_data = [x['properties'] for x in list_of_features]\n",
    "    \n",
    "    pd.DataFrame(new_data).to_csv(\"Zebra/presence_zebra_TEST_\" + str(s) + \".csv\",index=False) # <--------- #CHANGE OUTPUT CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loop through all of the random column's slices\n",
    "for s in numpy_int_seq:\n",
    "    filter_and_output_features(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.716px",
    "left": "1374.44px",
    "right": "20px",
    "top": "59.9943px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
